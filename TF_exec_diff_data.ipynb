{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This notebook's owner is a github user with the name yuki678. I merely modified a few scripts to make it compatible so it can be run uninterrupted and smoothly.\n",
    "# Many of the scripts used to run this notebook are copyrighted by the Tensorflow authors and licensed under the Apache License, Version 2.0 (the \"License\").\n",
    "# A copy of the license can be obtained at \n",
    "# http://www.apache.org/licenses/LICENSE-2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the README document first before running this notebook. It specifies what changes to make so all cells can be run be at once.\n",
    "# Make all the specified changes in the README before running any cells, then run until cell 12, make the specified changes and save them.\n",
    "# Before running the notebook the second time, make sure to comment out the line !rm -rf {repo_dir_path} in cell 11.\n",
    "# After these changes are made then you can run the entire notebook through the terminal command: \n",
    "# nohup jupyter nbconvert --to notebook --execute (notebookname).ipynb > (notebookname)_stdout.txt 2> (notebookname)_stderr.txt &\n",
    "# For this specific notebook the command would be :\n",
    "# nohup jupyter nbconvert --to notebook --execute TF_exF.ipynb > TF_exF_stdout.txt 2> TF_exF_stderr.txt &\n",
    "#This notebook is used for transfer learning. The pretrained models that can be selected are already trained on the coco dataset.\n",
    "# The data is already pre-labeled. Since this is transfer learning 100 \"samples\" per label is sufficient.\n",
    "# If you want to use your own data then you can use LabelImg to label the images and store the bounding box coordinates. The xml files \n",
    "# created by LabelImg are in Pascal VOC format. Go to driving-object-detection/images, delete the imported images and xml files and upload your own.\n",
    "# Also go to driving-object-detection/annotations and change the label_map.pbtxt file to match the structure of your object detection dataset.\n",
    "# In that text file create as many items as you need and assign them the corresponding name.\n",
    "# This entire notebook can be run interrupted through the terminal command: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/faizan_samad/doc_testing/Object-detection\n"
     ]
    }
   ],
   "source": [
    "cd ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorflow_version\n",
    "#First install the required packages\n",
    "# These are linux commands so change the terminal commands based on your OS. \n",
    "\n",
    "!pip install -q pillow lxml jupyter matplotlib cython pandas contextlib2\n",
    "!sudo apt-get install -qq protobuf-compiler\n",
    "!pip install -q pycocotools tf_slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/faizan_samad/doc_testing/Object-detection\n"
     ]
    }
   ],
   "source": [
    "#Ensure that you are in the correct directory first before cloning the driving object detection github repository\n",
    "#This cell creates the repository directory that already has the code for the models and the pipeline configuration files\n",
    "#Also additional subdirectories and file paths are created, they will be of use later.\n",
    "#THe original repo_url is repo_url = 'https://github.com/yuki678/driving-object-detection'\n",
    "#However I already cloned that repoistory into my own, although this is not necessary.\n",
    "#Change the directory to fit your workspace.\n",
    "%cd ./\n",
    "import os\n",
    "\n",
    "# Repo URL\n",
    "repo_url = 'https://github.com/Thearkhamknight/driving-object-detection'\n",
    "# repo_url = 'https://github.com/yuki678/driving-object-detection'\n",
    "# Models\n",
    "MODELS_CONFIG = {\n",
    "    'ssd_mobilenet_v2': {\n",
    "        'model_name': 'ssd_mobilenet_v2_320x320_coco17_tpu-8',\n",
    "        'model_path': '/models/tf2/my_ssd_mobilenet_v2/',\n",
    "        'pipeline_file': 'pipeline.config'\n",
    "    },\n",
    "    'ssd_mobilenet_v2_fpn': {\n",
    "        'model_name': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8',\n",
    "        'model_path': '/models/tf2/my_ssd_mobilenet_v2_fpnlite/',\n",
    "        'pipeline_file': 'pipeline.config'\n",
    "    },\n",
    "    'my_centernet_resnet50_v1_fpn': {\n",
    "        'model_name': 'centernet_resnet50_v1_fpn_512x512_coco17_tpu-8',\n",
    "        'model_path': '/models/tf2/my_centernet_resnet50_v1_fpn/',\n",
    "        'pipeline_file': 'pipeline.config'\n",
    "    },\n",
    "    'my_centernet_resnet101_v1_fpn': {\n",
    "        'model_name': 'centernet_resnet101_v1_fpn_512x512_coco17_tpu-8',\n",
    "        'model_path': '/models/tf2/my_centernet_resnet101_v1_fpn/',\n",
    "        'pipeline_file': 'pipeline.config'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Select a model to use.\n",
    "selected_model = 'my_centernet_resnet50_v1_fpn'\n",
    "\n",
    "model_name = MODELS_CONFIG[selected_model]['model_name']\n",
    "model_path = MODELS_CONFIG[selected_model]['model_path']\n",
    "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
    "\n",
    "# Set Repository Home Directory\n",
    "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n",
    "\n",
    "# Set Label Map (.pbtxt) path and pipeline.config path\n",
    "label_map_pbtxt_fname = repo_dir_path + '/annotations/label_map.pbtxt'\n",
    "pipeline_fname = repo_dir_path + model_path + pipeline_file\n",
    "# pipeline_fname ='/home/faizan_samad/testing/Ex_Scripts/pipeline.config'\n",
    "# Set .record path\n",
    "test_record_fname = repo_dir_path + '/annotations/test.record'\n",
    "train_record_fname = repo_dir_path + '/annotations/train.record'\n",
    "\n",
    "# Set output directories and clean up\n",
    "model_dir = repo_dir_path + '/training/'\n",
    "output_dir = repo_dir_path + '/exported-models/'\n",
    "\n",
    "!rm -rf {model_dir} {output_dir}\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/faizan_samad/doc_testing/Object-detection/driving-object-detection centernet_resnet50_v1_fpn_512x512_coco17_tpu-8 /models/tf2/my_centernet_resnet50_v1_fpn/\n"
     ]
    }
   ],
   "source": [
    "print(repo_dir_path,model_name,model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/faizan_samad/doc_testing/Object-detection\n"
     ]
    }
   ],
   "source": [
    "# Clone Tensorflow model repo\n",
    "#Again always ensure you are in the right directory before cloning or importing.\n",
    "# This cell clones the tensorflow models repository\n",
    "#Change the directory to fit your workspace.\n",
    "%cd ./\n",
    "\n",
    "# %cd /content\n",
    "!git clone --quiet https://github.com/tensorflow/models.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/faizan_samad/doc_testing/Object-detection/models/research\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compile protocol buffers\n",
    "#Change the directory to fit your workspace.\n",
    "%cd ./models/research\n",
    "!protoc object_detection/protos/*.proto --python_out=."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables\n",
    "import os\n",
    "os.environ['PATH'] += ':/testing/models:/testing/models/research/:/testing/models/research/slim/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Directory '.' is not installable. Neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
      "\u001b[0mTraceback (most recent call last):\n",
      "  File \"object_detection/builders/model_builder_test.py\", line 20, in <module>\n",
      "    from object_detection.builders import model_builder\n",
      "ModuleNotFoundError: No module named 'object_detection'\n"
     ]
    }
   ],
   "source": [
    "# Install libraries\n",
    "# Do not worry if this does not work. It is not necessary to run the rest of the cells.\n",
    "!pip install .\n",
    "# Test\n",
    "!python object_detection/builders/model_builder_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/faizan_samad/doc_testing/Object-detection\n"
     ]
    }
   ],
   "source": [
    "%cd -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/faizan_samad/doc_testing/Object-detection\n"
     ]
    }
   ],
   "source": [
    "# Coco Installation (Optional, required when using Coco Evaluation)\n",
    "#Change the directory to fit your workspace and the script path after !cp.\n",
    "%cd ./\n",
    "!git clone --quiet https://github.com/cocodataset/cocoapi.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/faizan_samad/doc_testing/Object-detection/cocoapi/PythonAPI\n",
      "python setup.py build_ext --inplace\n",
      "running build_ext\n",
      "cythoning pycocotools/_mask.pyx to pycocotools/_mask.c\n",
      "/opt/conda/lib/python3.7/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /home/faizan_samad/doc_testing/Object-detection/cocoapi/PythonAPI/pycocotools/_mask.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "building 'pycocotools._mask' extension\n",
      "creating build\n",
      "creating build/common\n",
      "creating build/temp.linux-x86_64-3.7\n",
      "creating build/temp.linux-x86_64-3.7/pycocotools\n",
      "gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/opt/conda/lib/python3.7/site-packages/numpy/core/include -I../common -I/opt/conda/include/python3.7m -c ../common/maskApi.c -o build/temp.linux-x86_64-3.7/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleDecode\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:46:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n",
      "       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:46:49:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
      "       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; \u001b[01;36m\u001b[Kv\u001b[m\u001b[K=!v; }}\n",
      "                                                 \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrPoly\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:166:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n",
      "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:166:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
      "   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); \u001b[01;36m\u001b[Kx\u001b[m\u001b[K[k]=x[0];\n",
      "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:167:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n",
      "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:167:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
      "   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); \u001b[01;36m\u001b[Ky\u001b[m\u001b[K[k]=y[0];\n",
      "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToString\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:212:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "       \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(more) c |= 0x20; c+=48; s[p++]=c;\n",
      "       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:212:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
      "       if(more) c |= 0x20; \u001b[01;36m\u001b[Kc\u001b[m\u001b[K+=48; s[p++]=c;\n",
      "                           \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrString\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K../common/maskApi.c:220:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "   \u001b[01;35m\u001b[Kwhile\u001b[m\u001b[K( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n",
      "   \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:220:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’\n",
      "   while( s[m] ) m++; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K=malloc(sizeof(uint)*m); m=0;\n",
      "                      \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:228:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
      "     \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n",
      "     \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K../common/maskApi.c:228:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
      "     if(m>2) x+=(long) cnts[m-2]; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K[m++]=(uint) x;\n",
      "                                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
      "gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/opt/conda/lib/python3.7/site-packages/numpy/core/include -I../common -I/opt/conda/include/python3.7m -c pycocotools/_mask.c -o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n",
      "creating build/lib.linux-x86_64-3.7\n",
      "creating build/lib.linux-x86_64-3.7/pycocotools\n",
      "gcc -pthread -shared -B /opt/conda/compiler_compat -L/opt/conda/lib -Wl,-rpath=/opt/conda/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.7/../common/maskApi.o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -o build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so\n",
      "copying build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so -> pycocotools\n",
      "rm -rf build\n",
      "cp: target './models/research/' is not a directory\n"
     ]
    }
   ],
   "source": [
    "%cd cocoapi/PythonAPI\n",
    "!make\n",
    "!cp -r pycocotools %cd ./models/research/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/faizan_samad/doc_testing/Object-detection\n"
     ]
    }
   ],
   "source": [
    "%cd -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/faizan_samad/doc_testing/Object-detection/models/research\n",
      "model name and dest_dir are  centernet_resnet50_v1_fpn_512x512_coco17_tpu-8 models/research/pretrained_model\n",
      "in first if\n",
      "downloading  http://download.tensorflow.org/models/object_detection/tf2/20200711/centernet_resnet50_v1_fpn_512x512_coco17_tpu-8.tar.gz\n",
      "centernet_resnet50_v1_fpn_512x512_coco17_tpu-8.tar.gz\n",
      "/home/faizan_samad/doc_testing/Object-detection/models/research/pretrained_model\n",
      "total 20K\n",
      "drwxr-x---  4 faizan_samad faizan_samad 4.0K Jul 11  2020 .\n",
      "drwxr-xr-x 23 faizan_samad faizan_samad 4.0K Apr 12 06:39 ..\n",
      "drwxr-x---  2 faizan_samad faizan_samad 4.0K Jul 10  2020 checkpoint\n",
      "-rw-r-----  1 faizan_samad faizan_samad 2.8K Jul 11  2020 pipeline.config\n",
      "drwxr-x---  3 faizan_samad faizan_samad 4.0K Jul 10  2020 saved_model\n",
      "fine_tune_checkpoint:  models/research/pretrained_model/checkpoint/ckpt-0\n"
     ]
    }
   ],
   "source": [
    "#If the model that was selected for some reason does not exist, this cell will download it from the tensorflow repository.\n",
    "#It also sets the file path for the checkpoints, which needs to be established before the model can be trained.\n",
    "#THe DEST_DIR is the path where the pretrained model is so under models/research/pretrained_model\n",
    "#Everything that precedes that file path is dependent on how you set up your directories.\n",
    "#Change the directory to fit your workspace. /models/research will be the same but anything preceding that will depend on the individual workspace.\n",
    "%cd ./models/research\n",
    "import sys \n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import urllib.request\n",
    "import tarfile\n",
    "a = sys.path[0]\n",
    "MODEL_FILE = model_name + '.tar.gz'\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/'\n",
    "DEST_DIR = 'models/research/pretrained_model'\n",
    "b = os.path.join(a, DEST_DIR)\n",
    "print('model name and dest_dir are ' ,model_name, DEST_DIR)\n",
    "if not (os.path.exists(MODEL_FILE)):\n",
    "    print('in first if')\n",
    "    print('downloading ', DOWNLOAD_BASE + MODEL_FILE)\n",
    "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
    "\n",
    "tar = tarfile.open(MODEL_FILE)\n",
    "tar.extractall()\n",
    "tar.close()\n",
    "\n",
    "\n",
    "print(MODEL_FILE)\n",
    "os.remove(MODEL_FILE)\n",
    "if (os.path.exists(DEST_DIR)):\n",
    "    print('in second if')\n",
    "    shutil.rmtree(DEST_DIR)\n",
    "os.rename(model_name, b)\n",
    "\n",
    "# Check downloaded files\n",
    "!echo {b}\n",
    "!ls -alh {b}\n",
    "\n",
    "# Set fine tune checkpoint\n",
    "fine_tune_checkpoint = os.path.join(DEST_DIR, \"checkpoint/ckpt-0\")\n",
    "print(\"fine_tune_checkpoint: \", fine_tune_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/faizan_samad/doc_testing/Object-detection\n"
     ]
    }
   ],
   "source": [
    "%cd -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/faizan_samad/doc_testing/Object-detection\n"
     ]
    }
   ],
   "source": [
    "%cd ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/faizan_samad/doc_testing/Object-detection\n",
      "Cloning into 'driving-object-detection'...\n",
      "remote: Enumerating objects: 2017, done.\u001b[K\n",
      "remote: Counting objects: 100% (665/665), done.\u001b[K\n",
      "remote: Compressing objects: 100% (635/635), done.\u001b[K\n",
      "remote: Total 2017 (delta 26), reused 657 (delta 24), pack-reused 1352\u001b[K\n",
      "Receiving objects: 100% (2017/2017), 323.38 MiB | 58.80 MiB/s, done.\n",
      "Resolving deltas: 100% (376/376), done.\n",
      "Checking out files: 100% (1777/1777), done.\n",
      "Cloning into 'Ex_Scripts'...\n",
      "remote: Enumerating objects: 17, done.\u001b[K\n",
      "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
      "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
      "remote: Total 17 (delta 4), reused 0 (delta 0), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (17/17), done.\n",
      "/home/faizan_samad/doc_testing/Object-detection/driving-object-detection\n",
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "#This cell clones all the content from the original driving object detection repository into the repository directory path.\n",
    "#It also checks that the label map and pipeline files exist.\n",
    "#Add the code: os.makedirs(model_dir, exist_ok=True). after cloning  and pulling the repositories. \n",
    "#This ensures that a training sub folder will be created.\n",
    "# The original clone command is !git clone {repo_url}\n",
    "#Since the repository is public you will not be prompted to give your github username and password.\n",
    "#But if you are prompted here is what you should do.\n",
    "\n",
    "#Instead of !git clone {repo_url} type the command:\n",
    "# !git clone https://<Username>:<Password>@github.com/yuki678/driving-object-detection.git\n",
    "#Change the directory to fit your workspace.\n",
    "import os\n",
    "%cd ./\n",
    "# Clean up\n",
    "\n",
    "!rm -rf {repo_dir_path}\n",
    "\n",
    "# Clone\n",
    "\n",
    "!git clone https://github.com/Thearkhamknight/driving-object-detection.git\n",
    "!git clone https://github.com/Thearkhamknight/Ex_Scripts.git\n",
    "# !git clone {repo_url} \n",
    "# Pull (just in case the repo already exists)\n",
    "%cd {repo_dir_path}\n",
    "!git pull\n",
    "\n",
    "# Check if label map and pipeline files exist\n",
    "assert os.path.isfile(label_map_pbtxt_fname), '`{}` not exist'.format(label_map_pbtxt_fname)\n",
    "assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "image_dir =r'/home/faizan_samad/doc_testing/Object-detection/driving-object-detection/images/'\n",
    "annotation_dir = r'/home/faizan_samad/doc_testing/Object-detection/driving-object-detection/annotations/'\n",
    "shutil.rmtree(image_dir)\n",
    "shutil.rmtree(annotation_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "with ZipFile('/home/faizan_samad/doc_testing/images.zip', 'r') as zipObj:\n",
    "   # Extract all the contents of zip file in different directory\n",
    "   zipObj.extractall('/home/faizan_samad/doc_testing/Object-detection/driving-object-detection/Images/')\n",
    "with ZipFile('/home/faizan_samad/doc_testing/train.zip', 'r') as zipObj:\n",
    "   # Extract all the contents of zip file in different directory\n",
    "   zipObj.extractall('/home/faizan_samad/doc_testing/Object-detection/driving-object-detection/Images/train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/faizan_samad/doc_testing/Object-detection/driving-object-detection/models/tf2/my_centernet_resnet50_v1_fpn/pipeline.config\n",
      "# CenterNet meta-architecture from the \"Objects as Points\" [1] paper\n",
      "# with the ResNet-v2-101 backbone. The ResNet backbone has a few differences\n",
      "# as compared to the one mentioned in the paper, hence the performance is\n",
      "# slightly worse. This config is TPU comptatible.\n",
      "# [1]: https://arxiv.org/abs/1904.07850\n",
      "#\n",
      "\n",
      "model {\n",
      "  center_net {\n",
      "    num_classes: 4\n",
      "    feature_extractor {\n",
      "      type: \"resnet_v1_50_fpn\"\n",
      "    }\n",
      "    image_resizer {\n",
      "      keep_aspect_ratio_resizer {\n",
      "        min_dimension: 512\n",
      "        max_dimension: 512\n",
      "        pad_to_max_dimension: true\n",
      "      }\n",
      "    }\n",
      "    object_detection_task {\n",
      "      task_loss_weight: 1.0\n",
      "      offset_loss_weight: 1.0\n",
      "      scale_loss_weight: 0.1\n",
      "      localization_loss {\n",
      "        l1_localization_loss {\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    object_center_params {\n",
      "      object_center_loss_weight: 1.0\n",
      "      min_box_overlap_iou: 0.7\n",
      "      max_box_predictions: 100\n",
      "      classification_loss {\n",
      "        penalty_reduced_logistic_focal_loss {\n",
      "          alpha: 2.0\n",
      "          beta: 4.0\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "train_config: {\n",
      "\n",
      "  batch_size: 8\n",
      "  num_steps: 10000\n",
      "\n",
      "  data_augmentation_options {\n",
      "    random_horizontal_flip {\n",
      "    }\n",
      "  }\n",
      "\n",
      "  data_augmentation_options {\n",
      "    random_crop_image {\n",
      "      min_aspect_ratio: 0.5\n",
      "      max_aspect_ratio: 1.7\n",
      "      random_coef: 0.25\n",
      "    }\n",
      "  }\n",
      "\n",
      "\n",
      "  data_augmentation_options {\n",
      "    random_adjust_hue {\n",
      "    }\n",
      "  }\n",
      "\n",
      "  data_augmentation_options {\n",
      "    random_adjust_contrast {\n",
      "    }\n",
      "  }\n",
      "\n",
      "  data_augmentation_options {\n",
      "    random_adjust_saturation {\n",
      "    }\n",
      "  }\n",
      "\n",
      "  data_augmentation_options {\n",
      "    random_adjust_brightness {\n",
      "    }\n",
      "  }\n",
      "\n",
      "  data_augmentation_options {\n",
      "    random_absolute_pad_image {\n",
      "       max_height_padding: 200\n",
      "       max_width_padding: 200\n",
      "       pad_color: [0, 0, 0]\n",
      "    }\n",
      "  }\n",
      "\n",
      "  optimizer {\n",
      "    adam_optimizer: {\n",
      "      epsilon: 1e-7  # Match tf.keras.optimizers.Adam's default.\n",
      "      learning_rate: {\n",
      "        cosine_decay_learning_rate {\n",
      "          learning_rate_base: 1e-3\n",
      "          total_steps: 10000\n",
      "          warmup_learning_rate: 2.5e-4\n",
      "          warmup_steps: 1000\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    use_moving_average: false\n",
      "  }\n",
      "  max_number_of_boxes: 3\n",
      "  unpad_groundtruth_tensors: false\n",
      "\n",
      "  fine_tune_checkpoint_version: V2\n",
      "  fine_tune_checkpoint: \"/home/faizan_samad/doc_testing/Object-detection/models/research/pretrained_model/checkpoint/ckpt-0\"\n",
      "  fine_tune_checkpoint_type: \"detection\"\n",
      "}\n",
      "\n",
      "train_input_reader: {\n",
      "  label_map_path: \"/home/faizan_samad/doc_testing/Object-detection/driving-object-detection/Annotations/label_map.pbtxt\"\n",
      "  tf_record_input_reader {\n",
      "    input_path: \"/home/faizan_samad/doc_testing/Object-detection/driving-object-detection/Annotations/train.record\"\n",
      "  }\n",
      "}\n",
      "\n",
      "eval_config: {\n",
      "  metrics_set: \"coco_detection_metrics\"\n",
      "  use_moving_averages: false\n",
      "  batch_size: 1;\n",
      "}\n",
      "\n",
      "eval_input_reader: {\n",
      "  label_map_path: \"/home/faizan_samad/doc_testing/Object-detection/driving-object-detection/Annotations/label_map.pbtxt\"\n",
      "  shuffle: false\n",
      "  num_epochs: 1\n",
      "  tf_record_input_reader {\n",
      "    input_path: \"/home/faizan_samad/doc_testing/Object-detection/driving-object-detection/Annotations/test.record\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Check pipeline config - update if required\n",
    "# Make sure that the pipeline is configured as needed. This cell checks that. If not you can manually go into the pipeline file and change it.\n",
    "#The fine tune checkpoint type should be \"detection\"\n",
    "# Ensure that the specified paths are completely correct with no typos.\n",
    "#For example specify the path to annotations with driving-object-detection/annotations, and any preceding directories.\n",
    "#Specify the checkpoint path as \"models/research/pretrained_model/checkpoint/ckpt-0\", and any preceding directories.\n",
    "\n",
    "\n",
    "print(pipeline_fname)\n",
    "!cat {pipeline_fname}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd {repo_dir_path}\n",
    "#This cell partitions the images into a train and test set.\n",
    "#The xml files were manually created using the LabelImg software.\n",
    "\n",
    "# Split images to train:test = 9:1\n",
    "!python scripts/partition_dataset.py -x -i images/ -r 0.1\n",
    "\n",
    "# Check test images\n",
    "!ls images/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell creates the train and test data from the xml files and converts it into a train and test csv file respectively.\n",
    "# Create train data:\n",
    "!python scripts/xml_to_csv.py -i images/train -o annotations/train_labels.csv\n",
    "\n",
    "# Create test data:\n",
    "!python scripts/xml_to_csv.py -i images/test -o annotations/test_labels.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/faizan_samad/doc_testing/Object-detection\n"
     ]
    }
   ],
   "source": [
    "%cd -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-12 06:48:27.877275: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-12 06:48:27.877325: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/faizan_samad/doc_testing/Object-detection/models/research\n",
      "2022-04-12 06:48:29.451202: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-04-12 06:48:29.451251: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-12 06:48:29.451275: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (production-instance-static-ip): /proc/driver/nvidia/version does not exist\n",
      "Successfully created the TFRecords: /home/faizan_samad/doc_testing/Object-detection/driving-object-detection/Annotations/train.record\n",
      "2022-04-12 06:48:40.040440: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-12 06:48:40.040489: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/faizan_samad/doc_testing/Object-detection/models/research\n",
      "2022-04-12 06:48:41.588255: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-04-12 06:48:41.588302: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-12 06:48:41.588324: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (production-instance-static-ip): /proc/driver/nvidia/version does not exist\n",
      "Traceback (most recent call last):\n",
      "  File \"Ex_Scripts/generate_tfrecord_v1.py\", line 135, in <module>\n",
      "    tf.compat.v1.app.run()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/platform/app.py\", line 36, in run\n",
      "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/absl/app.py\", line 312, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/absl/app.py\", line 258, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"Ex_Scripts/generate_tfrecord_v1.py\", line 126, in main\n",
      "    tf_example = create_tf_example(group, path, label_map)\n",
      "  File \"Ex_Scripts/generate_tfrecord_v1.py\", line 55, in create_tf_example\n",
      "    encoded_jpg = fid.read()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/lib/io/file_io.py\", line 114, in read\n",
      "    self._preread_check()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/lib/io/file_io.py\", line 77, in _preread_check\n",
      "    compat.path_to_str(self.__name), 1024 * 512)\n",
      "tensorflow.python.framework.errors_impl.NotFoundError: /home/faizan_samad/doc_testing/Object-detection/driving-object-detection/images/test/X_019.jpeg; No such file or directory\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "`/home/faizan_samad/doc_testing/Object-detection/driving-object-detection/annotations/test.record` not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3681/947068925.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'python Ex_Scripts/generate_tfrecord_v1.py --csv_input=driving-object-detection/Annotations/train_labels.csv --output_path=driving-object-detection/Annotations/train.record --img_path=driving-object-detection/Images/train/Train --label_map driving-object-detection/Annotations/label_map.pbtxt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'python Ex_Scripts/generate_tfrecord_v1.py --csv_input=driving-object-detection/Annotations/test_labels.csv --output_path=driving-object-detection/Annotations/test.record --img_path=driving-object-detection/images/test --label_map driving-object-detection/Annotations/label_map.pbtxt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_record_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'`{}` not exist'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_record_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_record_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'`{}` not exist'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_record_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: `/home/faizan_samad/doc_testing/Object-detection/driving-object-detection/annotations/test.record` not exist"
     ]
    }
   ],
   "source": [
    "#This cell converts the train labeled csv into a tf.record format for training. Make sure the parameters are specified correctly.\n",
    "#These scripts use functions defined in the object detection folder. Make sure the object detection folder (in models/research/object_detection)\n",
    "# path is correctly specified in order to use it. \n",
    "# I already added the lines:\n",
    "#import sys\n",
    "#sys.path.insert(1,\"/home/faizan_samad/testing/models/research\")\n",
    "# However change the file path to suit whatever preceding directories you might have\n",
    "# Change the script paths to fit your workspace. /Ex_Scripts/generate_tfrecord_v1.py will be the same but anything preceding that will depend on your setup.\n",
    "\n",
    "!python Ex_Scripts/generate_tfrecord_v1.py --csv_input=driving-object-detection/Annotations/train_labels.csv --output_path=driving-object-detection/Annotations/train.record --img_path=driving-object-detection/Images/train/Train --label_map driving-object-detection/Annotations/label_map.pbtxt\n",
    "!python Ex_Scripts/generate_tfrecord_v1.py --csv_input=driving-object-detection/Annotations/test_labels.csv --output_path=driving-object-detection/Annotations/test.record --img_path=driving-object-detection/Images/test --label_map driving-object-detection/Annotations/label_map.pbtxt\n",
    "assert os.path.isfile(test_record_fname), '`{}` not exist'.format(test_record_fname)\n",
    "assert os.path.isfile(train_record_fname), '`{}` not exist'.format(train_record_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set log directory for tensorboard to watch\n",
    "LOG_DIR = model_dir\n",
    "\n",
    "# Clean up the directory\n",
    "!rm -rf {LOG_DIR}/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use magic command to launch tensorboard within the notebook\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {LOG_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to have the latest project repo downloaded\n",
    "%cd {repo_dir_path}\n",
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING \n",
    "#This cell trains the model. Again make sure the object detection folder path is specified within these scripts otherwise it will not work.\n",
    "# I already added the lines:\n",
    "#import sys\n",
    "#sys.path.insert(1,\"/home/faizan_samad/testing/models/research\")\n",
    "# However change the file path to whatever preceding directories you might have.\n",
    "# Also change the script file path for your workspace. /Ex_Scripts/model_main_tf2.py will remain the same but whatever precedes that will have to change.\n",
    "#Change the directory to fit your workspace.\n",
    "\n",
    "!python Ex_Scripts/model_main_tf2.py \\\n",
    "    --pipeline_config_path={pipeline_fname} \\\n",
    "    --model_dir={model_dir} \\\n",
    "    --alsologtostderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the generated files\n",
    "# The line underneath !ls -lrt {model_dir} is unnecessary and can be commented out.\n",
    "!ls -lrt {model_dir}\n",
    "#content_test/models/research/object_detection/model_main_tf2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell evaluates the models performance on the test set\n",
    "#Change the directory to fit your workspace.\n",
    "# Also change the script file path for your workspace. /Ex_Scripts/model_main_tf2.py will remain the same but whatever precedes that will have to change.\n",
    "\n",
    "!python Ex_Scripts/model_main_tf2.py \\\n",
    "    --pipeline_config_path={pipeline_fname} \\\n",
    "    --model_dir={model_dir} \\\n",
    "    --checkpoint_dir={model_dir} \\\n",
    "    --eval_timeout=60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the generated files\n",
    "!ls -lrt {model_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell exports the  trained model to the exported-models folder\n",
    "#Make sure you use the magic command cd to go to the proper directory\n",
    "#Again ensure that you properly updated the system file path to recognize the \n",
    "#object_detection subfolder doing the same as when you ran model_main_tf2\n",
    "# I already added the lines:\n",
    "#import sys\n",
    "#sys.path.insert(1,\"/home/faizan_samad/testing/models/research\")\n",
    "# However change the file path to suit whatever preceding directories you might have\n",
    "# Also change the script file path for your workspace. /Ex_Scripts/exporter_main_v2.py will remain the same but whatever precedes that will have to change.\n",
    "\n",
    "!python Ex_Scripts/exporter_main_v2.py \\\n",
    "    --input_type image_tensor \\\n",
    "    --pipeline_config_path {pipeline_fname} \\\n",
    "    --trained_checkpoint_dir {model_dir} \\\n",
    "    --output_directory {output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the output files\n",
    "!echo {output_dir}\n",
    "!ls -lsr {output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd {repo_dir_path}\n",
    "!tar zcvf trained_model.tar.gz {output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Use images in test dir (update this if you have other images for inference)\n",
    "IMAGE_DIR = os.path.join(repo_dir_path, \"images\", \"test\")\n",
    "IMAGE_PATHS = []\n",
    "\n",
    "for file in os.listdir(IMAGE_DIR):\n",
    "    if file.endswith(\".jpg\") or file.endswith(\".png\"):\n",
    "        IMAGE_PATHS.append(os.path.join(IMAGE_DIR, file))\n",
    "\n",
    "IMAGE_PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure you append the object_detection folder to the system file path\n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(1,os.path.join(sys.path[0],'models','research'))\n",
    "import time\n",
    "import tensorflow as tf # Added as colab instance often crash\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "\n",
    "# Label Map path\n",
    "PATH_TO_LABELS = label_map_pbtxt_fname\n",
    "# Saved model path\n",
    "PATH_TO_SAVED_MODEL = os.path.join(output_dir, \"saved_model\")\n",
    "\n",
    "print('Loading model...', end='')\n",
    "start_time = time.time()\n",
    "\n",
    "# Load saved model and build the detection function\n",
    "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('Done! Took {} seconds'.format(elapsed_time))\n",
    "\n",
    "# Set category index\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
    "                                                                    use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n",
    "# This is required to display the images.\n",
    "%matplotlib inline \n",
    "\n",
    "for image_path in IMAGE_PATHS:\n",
    "\n",
    "    print('Running inference for {}... '.format(image_path), end='')\n",
    "\n",
    "    # Puts image into numpy array to feed into tensorflow graph.\n",
    "    # Note that by convention we put it into a numpy array with shape\n",
    "    #   (height, width, channels), where channels=3 for RGB.\n",
    "    image_np = np.array(Image.open(image_path))\n",
    "\n",
    "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "    input_tensor = tf.convert_to_tensor(image_np)\n",
    "\n",
    "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "    input_tensor = input_tensor[tf.newaxis, ...]\n",
    "\n",
    "    # input_tensor = np.expand_dims(image_np, 0)\n",
    "    detections = detect_fn(input_tensor)\n",
    "\n",
    "    # All outputs are batches tensors.\n",
    "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "    # We're only interested in the first num_detections.\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                   for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "          image_np_with_detections,\n",
    "          detections['detection_boxes'],\n",
    "          detections['detection_classes'],\n",
    "          detections['detection_scores'],\n",
    "          category_index,\n",
    "          use_normalized_coordinates=True,\n",
    "          max_boxes_to_draw=20,\n",
    "          min_score_thresh=.30,\n",
    "          agnostic_mode=False)\n",
    "\n",
    "    plt.figure(figsize = (12,8))\n",
    "    plt.imshow(image_np_with_detections)\n",
    "    print('Done')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.make_archive('executable', 'zip', '/home/faizan_samad/testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
