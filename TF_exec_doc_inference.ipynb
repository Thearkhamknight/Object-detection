{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This notebook's owner is a github user with the name yuki678. I merely modified a few scripts to make it compatible so it can be run uninterrupted and smoothly.\n",
    "# Many of the scripts used to run this notebook are copyrighted by the Tensorflow authors and licensed under the Apache License, Version 2.0 (the \"License\").\n",
    "# A copy of the license can be obtained at \n",
    "# http://www.apache.org/licenses/LICENSE-2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the README document first before running this notebook. It specifies what changes to make so all cells can be run be at once.\n",
    "# Make all the specified changes in the README before running any cells, then run until cell 12, make the specified changes and save them.\n",
    "# Before running the notebook the second time, make sure to comment out the line !rm -rf {repo_dir_path} in cell 11.\n",
    "# After these changes are made then you can run the entire notebook through the terminal command: \n",
    "# nohup jupyter nbconvert --to notebook --execute (notebookname).ipynb > (notebookname)_stdout.txt 2> (notebookname)_stderr.txt &\n",
    "# For this specific notebook the command would be :\n",
    "# nohup jupyter nbconvert --to notebook --execute TF_exF.ipynb > TF_exF_stdout.txt 2> TF_exF_stderr.txt &\n",
    "#This notebook is used for transfer learning. The pretrained models that can be selected are already trained on the coco dataset.\n",
    "# The data is already pre-labeled. Since this is transfer learning 100 \"samples\" per label is sufficient.\n",
    "# If you want to use your own data then you can use LabelImg to label the images and store the bounding box coordinates. The xml files \n",
    "# created by LabelImg are in Pascal VOC format. Go to driving-object-detection/images, delete the imported images and xml files and upload your own.\n",
    "# Also go to driving-object-detection/annotations and change the label_map.pbtxt file to match the structure of your object detection dataset.\n",
    "# In that text file create as many items as you need and assign them the corresponding name.\n",
    "# This entire notebook can be run interrupted through the terminal command: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorflow_version\n",
    "#First install the required packages\n",
    "# These are linux commands so change the terminal commands based on your OS. \n",
    "\n",
    "!pip install -q pillow lxml jupyter matplotlib cython pandas contextlib2\n",
    "!sudo apt-get install -qq protobuf-compiler\n",
    "!pip install -q pycocotools tf_slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensure that you are in the correct directory first before cloning the driving object detection github repository\n",
    "#This cell creates the repository directory that already has the code for the models and the pipeline configuration files\n",
    "#Also additional subdirectories and file paths are created, they will be of use later.\n",
    "#THe original repo_url is repo_url = 'https://github.com/yuki678/driving-object-detection'\n",
    "#However I already cloned that repoistory into my own, although this is not necessary.\n",
    "#Change the directory to fit your workspace.\n",
    "%cd ./\n",
    "import os\n",
    "\n",
    "# Repo URL\n",
    "repo_url = 'https://github.com/Thearkhamknight/driving-object-detection'\n",
    "# repo_url = 'https://github.com/yuki678/driving-object-detection'\n",
    "# Models\n",
    "MODELS_CONFIG = {\n",
    "    'ssd_mobilenet_v2': {\n",
    "        'model_name': 'ssd_mobilenet_v2_320x320_coco17_tpu-8',\n",
    "        'model_path': '/models/tf2/my_ssd_mobilenet_v2/',\n",
    "        'pipeline_file': 'pipeline.config'\n",
    "    },\n",
    "    'ssd_mobilenet_v2_fpn': {\n",
    "        'model_name': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8',\n",
    "        'model_path': '/models/tf2/my_ssd_mobilenet_v2_fpnlite/',\n",
    "        'pipeline_file': 'pipeline.config'\n",
    "    },\n",
    "    'my_centernet_resnet50_v1_fpn': {\n",
    "        'model_name': 'centernet_resnet50_v1_fpn_512x512_coco17_tpu-8',\n",
    "        'model_path': '/models/tf2/my_centernet_resnet50_v1_fpn/',\n",
    "        'pipeline_file': 'document_pipeline.config'\n",
    "    },\n",
    "    'my_centernet_resnet101_v1_fpn': {\n",
    "        'model_name': 'centernet_resnet101_v1_fpn_512x512_coco17_tpu-8',\n",
    "        'model_path': '/models/tf2/my_centernet_resnet101_v1_fpn/',\n",
    "        'pipeline_file': 'pipeline.config'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Select a model to use.\n",
    "selected_model = 'my_centernet_resnet50_v1_fpn'\n",
    "\n",
    "model_name = MODELS_CONFIG[selected_model]['model_name']\n",
    "model_path = MODELS_CONFIG[selected_model]['model_path']\n",
    "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
    "\n",
    "# Set Repository Home Directory\n",
    "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n",
    "\n",
    "# Set Label Map (.pbtxt) path and pipeline.config path\n",
    "label_map_pbtxt_fname = repo_dir_path + '/Annotations/label_map.pbtxt'\n",
    "pipeline_fname = repo_dir_path + model_path + pipeline_file\n",
    "# pipeline_fname ='/home/faizan_samad/testing/Ex_Scripts/pipeline.config'\n",
    "# Set .record path\n",
    "test_record_fname = repo_dir_path + '/Annotations/test.record'\n",
    "train_record_fname = repo_dir_path + '/Annotations/train.record'\n",
    "\n",
    "# Set output directories and clean up\n",
    "model_dir = repo_dir_path + '/training/'\n",
    "output_dir = repo_dir_path + '/exported-models/'\n",
    "\n",
    "!rm -rf {model_dir} {output_dir}\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(repo_dir_path,model_name,model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone Tensorflow model repo\n",
    "#Again always ensure you are in the right directory before cloning or importing.\n",
    "# This cell clones the tensorflow models repository\n",
    "#Change the directory to fit your workspace.\n",
    "%cd ./\n",
    "\n",
    "# %cd /content\n",
    "!git clone --quiet https://github.com/tensorflow/models.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compile protocol buffers\n",
    "#Change the directory to fit your workspace.\n",
    "%cd ./models/research\n",
    "!protoc object_detection/protos/*.proto --python_out=."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables\n",
    "import os\n",
    "os.environ['PATH'] += ':/testing/models:/testing/models/research/:/testing/models/research/slim/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install libraries\n",
    "# Do not worry if this does not work. It is not necessary to run the rest of the cells.\n",
    "!pip install .\n",
    "# Test\n",
    "!python object_detection/builders/model_builder_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coco Installation (Optional, required when using Coco Evaluation)\n",
    "#Change the directory to fit your workspace and the script path after !cp.\n",
    "%cd ./\n",
    "!git clone --quiet https://github.com/cocodataset/cocoapi.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd cocoapi/PythonAPI\n",
    "!make\n",
    "!cp -r pycocotools %cd ./models/research/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If the model that was selected for some reason does not exist, this cell will download it from the tensorflow repository.\n",
    "#It also sets the file path for the checkpoints, which needs to be established before the model can be trained.\n",
    "#THe DEST_DIR is the path where the pretrained model is so under models/research/pretrained_model\n",
    "#Everything that precedes that file path is dependent on how you set up your directories.\n",
    "#Change the directory to fit your workspace. /models/research will be the same but anything preceding that will depend on the individual workspace.\n",
    "%cd ./models/research\n",
    "import sys \n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import urllib.request\n",
    "import tarfile\n",
    "a = sys.path[0]\n",
    "MODEL_FILE = model_name + '.tar.gz'\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/'\n",
    "DEST_DIR = 'models/research/pretrained_model'\n",
    "b = os.path.join(a, DEST_DIR)\n",
    "print('model name and dest_dir are ' ,model_name, DEST_DIR)\n",
    "if not (os.path.exists(MODEL_FILE)):\n",
    "    print('in first if')\n",
    "    print('downloading ', DOWNLOAD_BASE + MODEL_FILE)\n",
    "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
    "\n",
    "tar = tarfile.open(MODEL_FILE)\n",
    "tar.extractall()\n",
    "tar.close()\n",
    "\n",
    "\n",
    "print(MODEL_FILE)\n",
    "os.remove(MODEL_FILE)\n",
    "if (os.path.exists(DEST_DIR)):\n",
    "    print('in second if')\n",
    "    shutil.rmtree(DEST_DIR)\n",
    "os.rename(model_name, b)\n",
    "\n",
    "# Check downloaded files\n",
    "!echo {b}\n",
    "!ls -alh {b}\n",
    "\n",
    "# Set fine tune checkpoint\n",
    "fine_tune_checkpoint = os.path.join(DEST_DIR, \"checkpoint/ckpt-0\")\n",
    "print(\"fine_tune_checkpoint: \", fine_tune_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell clones all the content from the original driving object detection repository into the repository directory path.\n",
    "#It also checks that the label map and pipeline files exist.\n",
    "#Add the code: os.makedirs(model_dir, exist_ok=True). after cloning  and pulling the repositories. \n",
    "#This ensures that a training sub folder will be created.\n",
    "# The original clone command is !git clone {repo_url}\n",
    "#Since the repository is public you will not be prompted to give your github username and password.\n",
    "#But if you are prompted here is what you should do.\n",
    "\n",
    "#Instead of !git clone {repo_url} type the command:\n",
    "# !git clone https://<Username>:<Password>@github.com/yuki678/driving-object-detection.git\n",
    "#Change the directory to fit your workspace.\n",
    "import os\n",
    "%cd ./\n",
    "# Clean up\n",
    "\n",
    "!rm -rf {repo_dir_path}\n",
    "\n",
    "# Clone\n",
    "\n",
    "!git clone https://github.com/Thearkhamknight/driving-object-detection.git\n",
    "!git clone https://github.com/Thearkhamknight/Ex_Scripts.git\n",
    "# !git clone {repo_url} \n",
    "# Pull (just in case the repo already exists)\n",
    "%cd {repo_dir_path}\n",
    "!git pull\n",
    "\n",
    "# Check if label map and pipeline files exist\n",
    "assert os.path.isfile(label_map_pbtxt_fname), '`{}` not exist'.format(label_map_pbtxt_fname)\n",
    "assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "image_dir =r'/home/faizan_samad/doc_testing/Object-detection/driving-object-detection/images/'\n",
    "annotation_dir = r'/home/faizan_samad/doc_testing/Object-detection/driving-object-detection/annotations/'\n",
    "shutil.rmtree(image_dir)\n",
    "shutil.rmtree(annotation_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "with ZipFile('/home/faizan_samad/doc_testing/images.zip', 'r') as zipObj:\n",
    "   # Extract all the contents of zip file in different directory\n",
    "   zipObj.extractall('/home/faizan_samad/doc_testing/Object-detection/driving-object-detection/Images/')\n",
    "with ZipFile('/home/faizan_samad/doc_testing/train.zip', 'r') as zipObj:\n",
    "   # Extract all the contents of zip file in different directory\n",
    "   zipObj.extractall('/home/faizan_samad/doc_testing/Object-detection/driving-object-detection/Images/train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check pipeline config - update if required\n",
    "# Make sure that the pipeline is configured as needed. This cell checks that. If not you can manually go into the pipeline file and change it.\n",
    "#The fine tune checkpoint type should be \"detection\"\n",
    "# Ensure that the specified paths are completely correct with no typos.\n",
    "#For example specify the path to annotations with driving-object-detection/annotations, and any preceding directories.\n",
    "#Specify the checkpoint path as \"models/research/pretrained_model/checkpoint/ckpt-0\", and any preceding directories.\n",
    "\n",
    "\n",
    "print(pipeline_fname)\n",
    "!cat {pipeline_fname}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd {repo_dir_path}\n",
    "# #This cell partitions the images into a train and test set.\n",
    "# #The xml files were manually created using the LabelImg software.\n",
    "\n",
    "# # Split images to train:test = 9:1\n",
    "# !python scripts/partition_dataset.py -x -i images/ -r 0.1\n",
    "\n",
    "# # Check test images\n",
    "# !ls images/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #This cell creates the train and test data from the xml files and converts it into a train and test csv file respectively.\n",
    "# # Create train data:\n",
    "# !python scripts/xml_to_csv.py -i images/train -o annotations/train_labels.csv\n",
    "\n",
    "# # Create test data:\n",
    "# !python scripts/xml_to_csv.py -i images/test -o annotations/test_labels.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell converts the train labeled csv into a tf.record format for training. Make sure the parameters are specified correctly.\n",
    "#These scripts use functions defined in the object detection folder. Make sure the object detection folder (in models/research/object_detection)\n",
    "# path is correctly specified in order to use it. \n",
    "# I already added the lines:\n",
    "#import sys\n",
    "#sys.path.insert(1,\"/home/faizan_samad/testing/models/research\")\n",
    "# However change the file path to suit whatever preceding directories you might have\n",
    "# Change the script paths to fit your workspace. /Ex_Scripts/generate_tfrecord_v1.py will be the same but anything preceding that will depend on your setup.\n",
    "\n",
    "!python Ex_Scripts/generate_tfrecord_v1.py --csv_input=driving-object-detection/Annotations/train_labels.csv --output_path=driving-object-detection/Annotations/train.record --img_path=driving-object-detection/Images/train/Train --label_map driving-object-detection/Annotations/label_map.pbtxt\n",
    "!python Ex_Scripts/generate_tfrecord_v1.py --csv_input=driving-object-detection/Annotations/test_labels.csv --output_path=driving-object-detection/Annotations/test.record --img_path=driving-object-detection/Images/Test --label_map driving-object-detection/Annotations/label_map.pbtxt\n",
    "assert os.path.isfile(test_record_fname), '`{}` not exist'.format(test_record_fname)\n",
    "assert os.path.isfile(train_record_fname), '`{}` not exist'.format(train_record_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set log directory for tensorboard to watch\n",
    "LOG_DIR = model_dir\n",
    "\n",
    "# Clean up the directory\n",
    "!rm -rf {LOG_DIR}/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use magic command to launch tensorboard within the notebook\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {LOG_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to have the latest project repo downloaded\n",
    "%cd {repo_dir_path}\n",
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING \n",
    "#This cell trains the model. Again make sure the object detection folder path is specified within these scripts otherwise it will not work.\n",
    "# I already added the lines:\n",
    "#import sys\n",
    "#sys.path.insert(1,\"/home/faizan_samad/testing/models/research\")\n",
    "# However change the file path to whatever preceding directories you might have.\n",
    "# Also change the script file path for your workspace. /Ex_Scripts/model_main_tf2.py will remain the same but whatever precedes that will have to change.\n",
    "#Change the directory to fit your workspace.\n",
    "\n",
    "!python Ex_Scripts/model_main_tf2.py \\\n",
    "    --pipeline_config_path={pipeline_fname} \\\n",
    "    --model_dir={model_dir} \\\n",
    "    --alsologtostderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the generated files\n",
    "# The line underneath !ls -lrt {model_dir} is unnecessary and can be commented out.\n",
    "!ls -lrt {model_dir}\n",
    "#content_test/models/research/object_detection/model_main_tf2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell evaluates the models performance on the test set\n",
    "#Change the directory to fit your workspace.\n",
    "# Also change the script file path for your workspace. /Ex_Scripts/model_main_tf2.py will remain the same but whatever precedes that will have to change.\n",
    "\n",
    "!python Ex_Scripts/model_main_tf2.py \\\n",
    "    --pipeline_config_path={pipeline_fname} \\\n",
    "    --model_dir={model_dir} \\\n",
    "    --checkpoint_dir={model_dir} \\\n",
    "    --eval_timeout=60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the generated files\n",
    "!ls -lrt {model_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell exports the  trained model to the exported-models folder\n",
    "#Make sure you use the magic command cd to go to the proper directory\n",
    "#Again ensure that you properly updated the system file path to recognize the \n",
    "#object_detection subfolder doing the same as when you ran model_main_tf2\n",
    "# I already added the lines:\n",
    "#import sys\n",
    "#sys.path.insert(1,\"/home/faizan_samad/testing/models/research\")\n",
    "# However change the file path to suit whatever preceding directories you might have\n",
    "# Also change the script file path for your workspace. /Ex_Scripts/exporter_main_v2.py will remain the same but whatever precedes that will have to change.\n",
    "\n",
    "!python Ex_Scripts/exporter_main_v2.py \\\n",
    "    --input_type image_tensor \\\n",
    "    --pipeline_config_path {pipeline_fname} \\\n",
    "    --trained_checkpoint_dir {model_dir} \\\n",
    "    --output_directory {output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the output files\n",
    "!echo {output_dir}\n",
    "!ls -lsr {output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd {repo_dir_path}\n",
    "!tar zcvf trained_model.tar.gz {output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Use images in test dir (update this if you have other images for inference)\n",
    "IMAGE_DIR = os.path.join(repo_dir_path, \"Images\", \"Test\")\n",
    "IMAGE_PATHS = []\n",
    "\n",
    "for file in os.listdir(IMAGE_DIR):\n",
    "    if file.endswith(\".jpg\") or file.endswith(\".png\") or file.endswith(\".jpeg\"):\n",
    "        IMAGE_PATHS.append(os.path.join(IMAGE_DIR, file))\n",
    "\n",
    "IMAGE_PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure you append the object_detection folder to the system file path\n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(1,os.path.join(sys.path[0],'models','research'))\n",
    "import time\n",
    "import tensorflow as tf # Added as colab instance often crash\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "\n",
    "# Label Map path\n",
    "PATH_TO_LABELS = label_map_pbtxt_fname\n",
    "# Saved model path\n",
    "PATH_TO_SAVED_MODEL = os.path.join(output_dir, \"saved_model\")\n",
    "print(PATH_TO_LABELS, PATH_TO_SAVED_MODEL)\n",
    "print('Loading model...', end='')\n",
    "start_time = time.time()\n",
    "\n",
    "# Load saved model and build the detection function\n",
    "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('Done! Took {} seconds'.format(elapsed_time))\n",
    "\n",
    "# Set category index\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
    "                                                                    use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(IMAGE_PATHS)\n",
    "IMAGE_PATHS_MIN = IMAGE_PATHS[::8]\n",
    "len(IMAGE_PATHS_MIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n",
    "# This is required to display the images.\n",
    "%matplotlib inline \n",
    "\n",
    "for image_path in IMAGE_PATHS_MIN:\n",
    "    # if np.array(Image.open(image_path)).dtype!='bool':\n",
    "\n",
    "    print('Running inference for {}... '.format(image_path), end='')\n",
    "    im = (Image.open(image_path))\n",
    "    im = im.convert(\"RGB\")\n",
    "\n",
    "        # Puts image into numpy array to feed into tensorflow graph.\n",
    "        # Note that by convention we put it into a numpy array with shape\n",
    "        #   (height, width, channels), where channels=3 for RGB.\n",
    "    image_np = np.array(im)\n",
    "        # print('dtype is' ,image_np.dtype)\n",
    "\n",
    "        # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "    input_tensor = tf.convert_to_tensor(image_np)\n",
    "        # print(input_tensor)\n",
    "\n",
    "        # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "    input_tensor = input_tensor[tf.newaxis, ...]\n",
    "        # print(input_tensor)\n",
    "\n",
    "        # input_tensor = np.expand_dims(image_np, 0)\n",
    "    detections = detect_fn(input_tensor)\n",
    "\n",
    "        # All outputs are batches tensors.\n",
    "        # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "        # We're only interested in the first num_detections.\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                       for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "        # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "              image_np_with_detections,\n",
    "              detections['detection_boxes'],\n",
    "              detections['detection_classes'],\n",
    "              detections['detection_scores'],\n",
    "              category_index,\n",
    "              use_normalized_coordinates=True,\n",
    "              max_boxes_to_draw=20,\n",
    "              min_score_thresh=.20,\n",
    "              agnostic_mode=False)\n",
    "\n",
    "    plt.figure(figsize = (12,8))\n",
    "    plt.imshow(image_np_with_detections)\n",
    "    print('Done')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# shutil.make_archive('executable', 'zip', '/home/faizan_samad/testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type((Image.open('/home/faizan_samad/doc_testing/Object-detection/driving-object-detection/Images/test/nist_r0108_01.png')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_path='/home/faizan_samad/doc_testing/Object-detection/driving-object-detection/Images/test/X_019.jpeg'\n",
    "# image_path2 = '/home/faizan_samad/doc_testing/Object-detection/driving-object-detection/Images/test/hcu72e00_2.png'\n",
    "# image_path3= '/home/faizan_samad/doc_testing/Object-detection/driving-object-detection/Images/test/nist_r0108_01.png'\n",
    "# img = Image.open(image_path)\n",
    "# img = img.convert(\"RGB\")\n",
    "# image_np = np.array(img)\n",
    "#         # print('dtype is' ,image_np.dtype)\n",
    "\n",
    "#         # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "# input_tensor = tf.convert_to_tensor(image_np)\n",
    "#         # print(input_tensor)\n",
    "\n",
    "#         # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "# input_tensor = input_tensor[tf.newaxis, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from PIL import Image\n",
    "# im = (Image.open(image_path))\n",
    "# Im = (Image.open(image_path2))\n",
    "# IMG = (Image.open(image_path3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im = im.convert(\"RGB\")\n",
    "# print(im.format)\n",
    "# print(im.size)\n",
    "# print(im.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Im.format)\n",
    "# print(Im.size)\n",
    "# print(Im.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMG = IMG.convert(\"RGB\")\n",
    "# print(IMG.format)\n",
    "# print(IMG.size)\n",
    "# print(IMG.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im = (Image.open(image_path3))\n",
    "# im = im.convert(\"RGB\")\n",
    "# image_np = np.array(im)\n",
    "#         # print('dtype is' ,image_np.dtype)\n",
    "\n",
    "#         # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "# input_tensor = tf.convert_to_tensor(image_np)\n",
    "#         # print(input_tensor)\n",
    "\n",
    "#         # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "# input_tensor = input_tensor[tf.newaxis, ...]\n",
    "#         # print(input_tensor)\n",
    "\n",
    "#         # input_tensor = np.expand_dims(image_np, 0)\n",
    "# detections = detect_fn(input_tensor)\n",
    "\n",
    "#         # All outputs are batches tensors.\n",
    "#         # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "#         # We're only interested in the first num_detections.\n",
    "# num_detections = int(detections.pop('num_detections'))\n",
    "# detections = {key: value[0, :num_detections].numpy()\n",
    "#                        for key, value in detections.items()}\n",
    "# detections['num_detections'] = num_detections\n",
    "\n",
    "#         # detection_classes should be ints.\n",
    "# detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "# image_np_with_detections = image_np.copy()\n",
    "\n",
    "# viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "#               image_np_with_detections,\n",
    "#               detections['detection_boxes'],\n",
    "#               detections['detection_classes'],\n",
    "#               detections['detection_scores'],\n",
    "#               category_index,\n",
    "#               use_normalized_coordinates=True,\n",
    "#               max_boxes_to_draw=20,\n",
    "#               min_score_thresh=.30,\n",
    "#               agnostic_mode=False)\n",
    "\n",
    "# plt.figure(figsize = (12,8))\n",
    "# plt.imshow(image_np_with_detections)\n",
    "# print('Done')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
